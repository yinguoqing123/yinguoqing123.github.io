---
layout: post
title:  Sigmod函数和GLM
categories: 数学基础 
tags:  Sigmod  GLM   
mathjax: true
---

* content
{:toc}

Logistic Regression中为什么sigmoid函数就可以表示后验概率？这是根据服从的概率分布而得。





## 指数分布族

$$
p(y;\eta) = b(y)exp(\eta^T T(y)-a(\eta))
$$

给定$a, b, T$后，$p(y;\eta)$是一簇关于$\eta$的分布，$\eta$称为规范参数

## 广义线性模型

普通线性模型:$y=\mathrm w^T \mathrm x$

广义线性：$f(y)=\mathrm w^T \mathrm x$,$f(y)$称为连接函数

满足以下假设：

* $ P(y ;Phi) \sim exponential(y;\eta) $
* $h_\theta (\mathrm x) = E(T(\mathrm y)\|\eta)$
* $\eta = \theta \cdot x$

包括高斯分布，伯努利分布等很多分布都满足指数分布族的表达。

## 逻辑回归和高斯判别

Logistic Regression只假设$P(y\| \mathrm ,\Phi)$在$\mathrm x$已知的情况下服从参数为$\Phi$的二项分布，而高斯判别假设$P(\mathrm x \|  y)$服从高斯分布。

若$P(\mathrm x \| y)$服从高斯分布，可推出$P( y \| \mathrm x)$的概率表达式是logistic函数，但反之未必，也有可能$P(\mathrm x \| y)$服从
泊松分布，二项分布等，所以逻辑回归有很好的鲁棒性。


## Sigmod函数形式

$$
f(x) = \frac {L} {1 + e^{-k(x - x_0)}}
$$

标准形式：$f(x) = \frac {1} {1 + e^(x-x_0)}$,在$[-6, 6]$区间上的图像如下：

<div align = "center"><img src="/photoes/201709_10/sigmoid_curve.png"></div>

* e = the natural logarithm base (also known as Euler's number),
* x0 = the x-value of the sigmoid's midpoint,
* L = the curve's maximum value, and
* k = the steepness of the curve.

### 微分

$f(x) = \frac {1} {1 + e^(x-x_0)}$

f^'(x) = f(x) (1 - f(x))

### 积分

$$
\int f(x) = \int \frac{e^x}{1+e^x} = log(1+e^x)
$$

## 参考

* [Ng讲义](http://cs229.stanford.edu/notes/)

