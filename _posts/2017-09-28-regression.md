---
layout: post
title:  回归总结
categories: 机器学习 
tags:  回归分析  
mathjax: true
---

* content
{:toc}

简单介绍回归的种类，不同正则化项的作用。





## 最小二乘

为什么在回归分析中都使用最小二乘，这是假设噪声是高斯白噪声，按照最大化贝叶斯后验概率求解而得，即使两个向量的距离最小，若对噪声的假设
不同，那么可以不用最小二乘。

## 正则化项

为了获得模型的一些结构，会加入正则化项，最常用的是L1和L2范数。正则化项也可以防止过拟合。

L2范数可以限制$\mathrm w$的每个分量都接近与0

L1范数可以稀疏化$\mathrm w$，当样本数远小于特征数时，应当使用L1范数，因为实际上特征之间存在线性关系，应当是$\mathrm w$尽量稀疏化

[参考](http://blog.csdn.net/qiao1245/article/details/53020882)

## 各种回归

### Ridge回归

### Lasso回归

### Logistic回归

### 弹性网络