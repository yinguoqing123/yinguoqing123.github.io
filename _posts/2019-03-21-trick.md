---
layout: post
title:  深度学习中trick
categories: Trick
tags:  CV
mathjax: true
---

* content
{:toc}

深度学习中看到的小trick，不一定有用。





## LSR

label smoothing regularization，提升模型泛化能力，防止模型过于自信，是不是适用于小数据集。

## maxout

maxout激活函数，适合和dropout一起使用

## focal loss

解决正负样本比例不平衡，当负样本很多，同时大部分负样本loss已经很小，但是bp时由于数量太多，仍然求导仍然占主导作用。

当识别对象很小时，one stage算法中候选框负样本容易过多。

## OHEM 

同样为解决数量不平衡，重点关注loss大的哪些样本，即哪些比较难以分类的样本。

## deformable convolution

当样本发生旋转，缩放等操作还需要能被识别，一种做法是扩充数据集，另一种做法是可形变卷积，卷积框的形状不是规则的正方形，而是增加offset，
未知参数除了卷积核还有对应的offset。

